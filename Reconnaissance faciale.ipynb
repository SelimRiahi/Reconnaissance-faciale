{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3369c819-7513-4f84-af01-3989bf7d447f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 700 images for 50 people\n",
      "Images per person: 14.0\n",
      "\n",
      "Evaluation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.29      0.44         7\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       1.00      0.18      0.31        11\n",
      "           4       1.00      0.08      0.15        12\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       1.00      0.22      0.36         9\n",
      "           7       1.00      0.08      0.14        13\n",
      "           8       1.00      0.10      0.18        10\n",
      "           9       1.00      0.10      0.18        10\n",
      "          10       1.00      0.10      0.18        10\n",
      "          11       1.00      0.08      0.15        12\n",
      "          12       0.00      0.00      0.00        12\n",
      "          13       1.00      0.50      0.67         6\n",
      "          14       1.00      0.18      0.31        11\n",
      "          15       1.00      0.20      0.33        10\n",
      "          16       1.00      0.25      0.40        16\n",
      "          17       1.00      0.11      0.20         9\n",
      "          18       1.00      0.08      0.14        13\n",
      "          19       1.00      0.14      0.25        14\n",
      "          20       1.00      0.18      0.30        17\n",
      "          21       0.00      0.00      0.00        12\n",
      "          22       1.00      0.11      0.20         9\n",
      "          23       1.00      0.18      0.30        17\n",
      "          24       0.00      0.00      0.00        16\n",
      "          25       1.00      0.08      0.14        13\n",
      "          26       1.00      0.20      0.33        10\n",
      "          27       1.00      0.11      0.20         9\n",
      "          28       1.00      0.10      0.18        10\n",
      "          29       1.00      0.17      0.29        12\n",
      "          30       1.00      0.20      0.33        10\n",
      "          31       0.00      0.00      0.00        12\n",
      "          32       1.00      0.29      0.44         7\n",
      "          33       1.00      0.27      0.43        11\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       1.00      0.20      0.33        10\n",
      "          36       1.00      0.14      0.25        14\n",
      "          37       1.00      0.12      0.22        16\n",
      "          38       0.00      0.00      0.00        15\n",
      "          39       1.00      0.30      0.46        10\n",
      "          40       1.00      0.23      0.38        13\n",
      "          41       0.00      0.00      0.00        11\n",
      "          42       1.00      0.07      0.12        15\n",
      "          43       1.00      0.08      0.15        12\n",
      "          44       1.00      0.07      0.13        14\n",
      "          45       1.00      0.11      0.20         9\n",
      "          46       1.00      0.07      0.12        15\n",
      "          47       1.00      0.11      0.20         9\n",
      "          48       1.00      0.25      0.40         8\n",
      "          49       0.00      0.00      0.00        10\n",
      "          50       0.01      1.00      0.02         5\n",
      "\n",
      "    accuracy                           0.13       560\n",
      "   macro avg       0.78      0.15      0.21       560\n",
      "weighted avg       0.79      0.13      0.20       560\n",
      "\n",
      "\n",
      "Improved model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import joblib\n",
    "\n",
    "def load_dataset(path):\n",
    "    \"\"\"Load images with enhanced error handling\"\"\"\n",
    "    images, labels = [], []\n",
    "    min_images_per_person = 5  # Minimum images required per person\n",
    "    \n",
    "    for filename in sorted(os.listdir(path)):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg')):\n",
    "            try:\n",
    "                person_id = int(filename.split('-')[0])\n",
    "                img_path = os.path.join(path, filename)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                \n",
    "                if img is not None:\n",
    "                    img = cv2.resize(img, (128, 128))\n",
    "                    images.append(img)\n",
    "                    labels.append(person_id)\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    # Filter out people with too few images\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    valid_labels = unique[counts >= min_images_per_person]\n",
    "    filtered_images = []\n",
    "    filtered_labels = []\n",
    "    \n",
    "    for img, label in zip(images, labels):\n",
    "        if label in valid_labels:\n",
    "            filtered_images.append(img)\n",
    "            filtered_labels.append(label)\n",
    "    \n",
    "    print(f\"\\nLoaded {len(filtered_images)} images for {len(valid_labels)} people\")\n",
    "    print(f\"Images per person: {len(filtered_images)/len(valid_labels):.1f}\")\n",
    "    return np.array(filtered_images), np.array(filtered_labels)\n",
    "\n",
    "def augment_images(images, labels):\n",
    "    \"\"\"Create additional training samples\"\"\"\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1\n",
    "    )\n",
    "    \n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "    \n",
    "    for img, label in zip(images, labels):\n",
    "        img = img.reshape(128, 128, 1)\n",
    "        # Generate 3 augmented versions\n",
    "        for _ in range(3):\n",
    "            transformed = datagen.random_transform(img)\n",
    "            augmented_images.append(transformed[:,:,0])\n",
    "            augmented_labels.append(label)\n",
    "    \n",
    "    return np.vstack([images, augmented_images]), np.concatenate([labels, augmented_labels])\n",
    "\n",
    "def extract_features(images):\n",
    "    \"\"\"Enhanced feature extraction\"\"\"\n",
    "    # CNN Features\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "    model = Model(inputs=base_model.input, outputs=base_model.get_layer('block5_pool').output)\n",
    "    \n",
    "    rgb_images = np.repeat(images[..., np.newaxis], 3, axis=-1)\n",
    "    cnn_features = model.predict(rgb_images, batch_size=16, verbose=0).reshape(len(images), -1)\n",
    "    \n",
    "    # LBP Features\n",
    "    lbp_features = []\n",
    "    for img in images:\n",
    "        lbp = local_binary_pattern((img * 255).astype(np.uint8), 24, 3, method='uniform')\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 26))\n",
    "        lbp_features.append(hist / (hist.sum() + 1e-6))\n",
    "    \n",
    "    return cnn_features, np.array(lbp_features)\n",
    "\n",
    "def train_and_evaluate(X, y):\n",
    "    \"\"\"Improved training with class weighting\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Calculate class weights\n",
    "    unique, counts = np.unique(y_train, return_counts=True)\n",
    "    class_weights = {cls: len(y_train)/(len(unique)*count) for cls, count in zip(unique, counts)}\n",
    "    \n",
    "    svm = SVC(\n",
    "        C=10, \n",
    "        gamma=0.01, \n",
    "        kernel='rbf', \n",
    "        class_weight=class_weights,  # Balance classes\n",
    "        probability=True\n",
    "    )\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    y_pred = svm.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    \n",
    "    return svm\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # 1. Load and filter data\n",
    "        dataset_path = r\"C:\\Users\\Selim\\Downloads\\originalimages_part1\"\n",
    "        images, labels = load_dataset(dataset_path)\n",
    "        \n",
    "        # 2. Augment data\n",
    "        images, labels = augment_images(images, labels)\n",
    "        images = preprocess_images(images)\n",
    "        \n",
    "        # 3. Feature extraction\n",
    "        cnn_feat, lbp_feat = extract_features(images)\n",
    "        X = np.hstack((\n",
    "            StandardScaler().fit_transform(cnn_feat),\n",
    "            StandardScaler().fit_transform(lbp_feat)\n",
    "        ))\n",
    "        \n",
    "        # 4. Reduce dimensions\n",
    "        X_reduced = PCA(n_components=100).fit_transform(X)\n",
    "        \n",
    "        # 5. Train and save\n",
    "        model = train_and_evaluate(X_reduced, labels)\n",
    "        joblib.dump(model, 'improved_face_model.pkl')\n",
    "        print(\"\\nImproved model saved successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6697807d-e015-4dd3-a481-f06b78b4f0c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and filtering dataset...\n",
      "\n",
      "Loaded 700 images for 50 people\n",
      "Average images per person: 14.0\n",
      "Augmenting dataset...\n",
      "Preprocessing images...\n",
      "Extracting features...\n",
      "Reducing dimensions...\n",
      "Training model...\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.857     0.857     0.857        14\n",
      "           2      0.812     0.929     0.867        14\n",
      "           3      1.000     1.000     1.000        14\n",
      "           4      1.000     0.929     0.963        14\n",
      "           5      0.917     0.786     0.846        14\n",
      "           6      1.000     0.857     0.923        14\n",
      "           7      1.000     0.929     0.963        14\n",
      "           8      1.000     0.929     0.963        14\n",
      "           9      1.000     1.000     1.000        14\n",
      "          10      1.000     0.857     0.923        14\n",
      "          11      1.000     1.000     1.000        14\n",
      "          12      0.923     0.857     0.889        14\n",
      "          13      1.000     0.929     0.963        14\n",
      "          14      0.917     0.786     0.846        14\n",
      "          15      1.000     0.929     0.963        14\n",
      "          16      1.000     0.929     0.963        14\n",
      "          17      0.929     0.929     0.929        14\n",
      "          18      0.929     0.929     0.929        14\n",
      "          19      1.000     1.000     1.000        14\n",
      "          20      0.923     0.857     0.889        14\n",
      "          21      1.000     0.929     0.963        14\n",
      "          22      0.857     0.857     0.857        14\n",
      "          23      1.000     0.857     0.923        14\n",
      "          24      0.867     0.929     0.897        14\n",
      "          25      1.000     0.857     0.923        14\n",
      "          26      0.209     1.000     0.346        14\n",
      "          27      1.000     1.000     1.000        14\n",
      "          28      1.000     0.929     0.963        14\n",
      "          29      1.000     0.857     0.923        14\n",
      "          30      1.000     0.857     0.923        14\n",
      "          31      1.000     0.714     0.833        14\n",
      "          32      1.000     0.786     0.880        14\n",
      "          33      1.000     0.786     0.880        14\n",
      "          34      0.909     0.714     0.800        14\n",
      "          35      0.917     0.786     0.846        14\n",
      "          36      0.867     0.929     0.897        14\n",
      "          37      1.000     0.929     0.963        14\n",
      "          38      0.867     0.929     0.897        14\n",
      "          39      0.917     0.786     0.846        14\n",
      "          40      1.000     1.000     1.000        14\n",
      "          41      1.000     0.714     0.833        14\n",
      "          42      0.824     1.000     0.903        14\n",
      "          43      0.933     1.000     0.966        14\n",
      "          44      0.917     0.786     0.846        14\n",
      "          45      0.933     1.000     0.966        14\n",
      "          46      1.000     0.786     0.880        14\n",
      "          47      1.000     0.857     0.923        14\n",
      "          48      1.000     0.643     0.783        14\n",
      "          49      1.000     0.857     0.923        14\n",
      "          50      0.923     0.857     0.889        14\n",
      "\n",
      "    accuracy                          0.883       700\n",
      "   macro avg      0.943     0.883     0.903       700\n",
      "weighted avg      0.943     0.883     0.903       700\n",
      "\n",
      "All models saved successfully!\n",
      "\n",
      "Optimized model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import joblib\n",
    "\n",
    "def load_and_filter_dataset(path, min_images=10):\n",
    "    \"\"\"Load images and ensure minimum samples per class\"\"\"\n",
    "    images, labels = [], []\n",
    "    \n",
    "    # Count images per person first\n",
    "    person_counts = {}\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg')):\n",
    "            try:\n",
    "                person_id = int(filename.split('-')[0])\n",
    "                person_counts[person_id] = person_counts.get(person_id, 0) + 1\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    # Only keep persons with enough images\n",
    "    valid_persons = {pid for pid, count in person_counts.items() if count >= min_images}\n",
    "    \n",
    "    # Load images for valid persons only\n",
    "    for filename in sorted(os.listdir(path)):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg')):\n",
    "            try:\n",
    "                person_id = int(filename.split('-')[0])\n",
    "                if person_id in valid_persons:\n",
    "                    img = cv2.imread(os.path.join(path, filename), cv2.IMREAD_GRAYSCALE)\n",
    "                    if img is not None:\n",
    "                        img = cv2.resize(img, (128, 128))\n",
    "                        images.append(img)\n",
    "                        labels.append(person_id)\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    print(f\"\\nLoaded {len(images)} images for {len(valid_persons)} people\")\n",
    "    print(f\"Average images per person: {len(images)/len(valid_persons):.1f}\")\n",
    "    \n",
    "    if len(valid_persons) < 2:\n",
    "        raise ValueError(\"Not enough valid persons for training (need at least 2)\")\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "def augment_data(images, labels, augment_factor=4):\n",
    "    \"\"\"Generate synthetic training data\"\"\"\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.15,\n",
    "        height_shift_range=0.15,\n",
    "        zoom_range=0.15,\n",
    "        brightness_range=[0.8, 1.2]\n",
    "    )\n",
    "    \n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "    \n",
    "    for img, label in zip(images, labels):\n",
    "        img = img.reshape(128, 128, 1)\n",
    "        # Generate augmented versions\n",
    "        for _ in range(augment_factor):\n",
    "            transformed = datagen.random_transform(img)\n",
    "            augmented_images.append(transformed[:,:,0])\n",
    "            augmented_labels.append(label)\n",
    "    \n",
    "    # Combine original and augmented data\n",
    "    all_images = np.concatenate([images, np.array(augmented_images)])\n",
    "    all_labels = np.concatenate([labels, np.array(augmented_labels)])\n",
    "    \n",
    "    return all_images, all_labels\n",
    "\n",
    "def extract_enhanced_features(images):\n",
    "    \"\"\"Improved feature extraction with normalization\"\"\"\n",
    "    # CNN Features\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "    model = Model(inputs=base_model.input, outputs=base_model.get_layer('block5_pool').output)\n",
    "    \n",
    "    rgb_images = np.repeat(images[..., np.newaxis], 3, axis=-1)\n",
    "    cnn_features = model.predict(rgb_images, batch_size=32, verbose=0)\n",
    "    cnn_features = cnn_features.reshape(cnn_features.shape[0], -1)\n",
    "    \n",
    "    # Enhanced LBP Features\n",
    "    lbp_features = []\n",
    "    for img in images:\n",
    "        img_uint8 = (img * 255).astype(np.uint8)\n",
    "        lbp = local_binary_pattern(img_uint8, 24, 3, method='uniform')\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 27))  # Extra bin\n",
    "        hist = hist.astype(\"float32\") / (hist.sum() + 1e-6)\n",
    "        lbp_features.append(hist)\n",
    "    \n",
    "    return cnn_features, np.array(lbp_features)\n",
    "\n",
    "def train_optimized_model(X, y):\n",
    "    \"\"\"Enhanced training with balanced classes\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # Balance class weights\n",
    "    unique, counts = np.unique(y_train, return_counts=True)\n",
    "    class_weights = {u: sum(counts)/(len(counts)*c) for u, c in zip(unique, counts)}\n",
    "    \n",
    "    # Optimized SVM\n",
    "    svm = SVC(\n",
    "        C=5,  # Reduced regularization\n",
    "        gamma='scale',\n",
    "        kernel='rbf',\n",
    "        class_weight=class_weights,\n",
    "        probability=True,\n",
    "        decision_function_shape='ovr'  # Better for multi-class\n",
    "    )\n",
    "    \n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Enhanced evaluation\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    y_pred = svm.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, zero_division=0, digits=3))\n",
    "    \n",
    "    return svm\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # 1. Load and filter data\n",
    "        dataset_path = r\"C:\\Users\\Selim\\Downloads\\originalimages_part1\"\n",
    "        print(\"Loading and filtering dataset...\")\n",
    "        images, labels = load_and_filter_dataset(dataset_path, min_images=10)\n",
    "        \n",
    "        # 2. Augment data\n",
    "        print(\"Augmenting dataset...\")\n",
    "        images, labels = augment_data(images, labels)\n",
    "        \n",
    "        # 3. Preprocess\n",
    "        print(\"Preprocessing images...\")\n",
    "        images = images / 255.0  # Normalization\n",
    "        for i in range(len(images)):\n",
    "            images[i] = cv2.equalizeHist((images[i] * 255).astype(np.uint8)) / 255.0\n",
    "        \n",
    "        # 4. Feature extraction\n",
    "        print(\"Extracting features...\")\n",
    "        cnn_feat, lbp_feat = extract_enhanced_features(images)\n",
    "        X = np.hstack((\n",
    "            StandardScaler().fit_transform(cnn_feat),\n",
    "            StandardScaler().fit_transform(lbp_feat)\n",
    "        ))\n",
    "        \n",
    "        # 5. Dimensionality reduction\n",
    "        print(\"Reducing dimensions...\")\n",
    "        X_reduced = PCA(n_components=0.95, svd_solver='full').fit_transform(X)  # Keep 95% variance\n",
    "        \n",
    "        # 6. Train and save\n",
    "        print(\"Training model...\")\n",
    "        model = train_optimized_model(X_reduced, labels)\n",
    "        joblib.dump(model, 'optimized_face_model.pkl')\n",
    "        pca = PCA(n_components=0.95, svd_solver='full').fit(X)\n",
    "        scaler_cnn = StandardScaler().fit(cnn_feat)\n",
    "        scaler_lbp = StandardScaler().fit(lbp_feat)\n",
    "\n",
    "        joblib.dump(pca, 'pca.pkl')\n",
    "        joblib.dump(scaler_cnn, 'scaler_cnn.pkl')\n",
    "        joblib.dump(scaler_lbp, 'scaler_lbp.pkl')\n",
    "        print(\"All models saved successfully!\")\n",
    "        print(\"\\nOptimized model saved successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {str(e)}\")\n",
    "        print(\"Common fixes:\")\n",
    "        print(\"- Check your images are named like '1-01.jpg', '1-02.jpg'\")\n",
    "        print(\"- Ensure you have at least 10 images per person\")\n",
    "        print(\"- Verify the folder contains only face images\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01b6f846-d9bc-4cbb-989c-8659a90887ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during testing: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Selim\\\\pca.pkl'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 0.0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_single_image(image_path):\n",
    "    \"\"\"Test the model on a single image\"\"\"\n",
    "    try:\n",
    "        # Load all models from your user directory\n",
    "        model_dir = r\"C:\\Users\\Selim\"  # Where your .pkl files are saved\n",
    "        svm = joblib.load(os.path.join(model_dir, 'optimized_face_model.pkl'))\n",
    "        pca = joblib.load(os.path.join(model_dir, 'pca.pkl'))\n",
    "        scaler_cnn = joblib.load(os.path.join(model_dir, 'scaler_cnn.pkl'))\n",
    "        scaler_lbp = joblib.load(os.path.join(model_dir, 'scaler_lbp.pkl'))\n",
    "        \n",
    "        # Load and preprocess image\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not read image at {image_path}\")\n",
    "            \n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        img = img / 255.0\n",
    "        img = cv2.equalizeHist((img * 255).astype(np.uint8)) / 255.0\n",
    "        \n",
    "        # Extract features\n",
    "        cnn_feat = extract_cnn_features(np.array([img]))\n",
    "        lbp_feat = extract_lbp_features(np.array([img]))\n",
    "        \n",
    "        # Normalize and transform\n",
    "        features = np.hstack([\n",
    "            scaler_cnn.transform(cnn_feat),\n",
    "            scaler_lbp.transform(lbp_feat)\n",
    "        ])\n",
    "        reduced_features = pca.transform(features)\n",
    "        \n",
    "        # Predict\n",
    "        person_id = svm.predict(reduced_features)[0]\n",
    "        confidence = svm.predict_proba(reduced_features).max()\n",
    "        \n",
    "        print(f\"Predicted: Person {person_id} ({confidence*100:.1f}% confidence)\")\n",
    "        return person_id, confidence\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during testing: {str(e)}\")\n",
    "        return None, 0.0\n",
    "\n",
    "# Usage:\n",
    "test_single_image(r\"C:\\Users\\Selim\\Downloads\\originalimages_part1\\47-03.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "555a6355-6fb6-40e1-a297-b7b102e1cca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking C:\\Users\\Selim:\n",
      " - optimized_face_model.pkl: FOUND\n",
      " - pca.pkl: missing\n",
      " - scaler_cnn.pkl: missing\n",
      " - scaler_lbp.pkl: missing\n",
      "\n",
      "Checking C:\\Users\\Selim\\Documents:\n",
      " - optimized_face_model.pkl: missing\n",
      " - pca.pkl: missing\n",
      " - scaler_cnn.pkl: missing\n",
      " - scaler_lbp.pkl: missing\n",
      "\n",
      "Checking C:\\Users\\Selim\\OneDrive\\Bureau\\gestion-proj\\gestion-de-projets:\n",
      " - optimized_face_model.pkl: FOUND\n",
      " - pca.pkl: FOUND\n",
      " - scaler_cnn.pkl: FOUND\n",
      " - scaler_lbp.pkl: FOUND\n",
      "\n",
      "Checking C:\\Users\\Selim\\Downloads\\originalimages_part1:\n",
      " - optimized_face_model.pkl: missing\n",
      " - pca.pkl: missing\n",
      " - scaler_cnn.pkl: missing\n",
      " - scaler_lbp.pkl: missing\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check common locations\n",
    "search_paths = [\n",
    "    r\"C:\\Users\\Selim\",\n",
    "    r\"C:\\Users\\Selim\\Documents\",\n",
    "    os.getcwd(),  # Current working directory\n",
    "    r\"C:\\Users\\Selim\\Downloads\\originalimages_part1\"\n",
    "]\n",
    "\n",
    "for path in search_paths:\n",
    "    print(f\"\\nChecking {path}:\")\n",
    "    for file in ['optimized_face_model.pkl', 'pca.pkl', 'scaler_cnn.pkl', 'scaler_lbp.pkl']:\n",
    "        full_path = os.path.join(path, file)\n",
    "        print(f\" - {file}: {'FOUND' if os.path.exists(full_path) else 'missing'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3f1f784-60bb-4afb-b874-e4e36410a870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: Person 32 (97.0% confidence)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 0.9697062810756335)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "# Set the correct model directory\n",
    "MODEL_DIR = r\"C:\\Users\\Selim\\OneDrive\\Bureau\\gestion-proj\\gestion-de-projets\"\n",
    "\n",
    "def extract_cnn_features(images):\n",
    "    \"\"\"Your existing CNN feature extraction function\"\"\"\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "    model = Model(inputs=base_model.input, outputs=base_model.get_layer('block5_pool').output)\n",
    "    rgb_images = np.repeat(images[..., np.newaxis], 3, axis=-1)\n",
    "    return model.predict(rgb_images, verbose=0).reshape(len(images), -1)\n",
    "\n",
    "def extract_lbp_features(images):\n",
    "    \"\"\"Your existing LBP feature extraction\"\"\"\n",
    "    lbp_features = []\n",
    "    for img in images:\n",
    "        lbp = local_binary_pattern((img * 255).astype(np.uint8), 24, 3, method='uniform')\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 27))\n",
    "        lbp_features.append(hist.astype(\"float32\") / (hist.sum() + 1e-6))\n",
    "    return np.array(lbp_features)\n",
    "\n",
    "def test_single_image(image_path):\n",
    "    try:\n",
    "        # Load all models from the correct directory\n",
    "        svm = joblib.load(os.path.join(MODEL_DIR, 'optimized_face_model.pkl'))\n",
    "        pca = joblib.load(os.path.join(MODEL_DIR, 'pca.pkl'))\n",
    "        scaler_cnn = joblib.load(os.path.join(MODEL_DIR, 'scaler_cnn.pkl'))\n",
    "        scaler_lbp = joblib.load(os.path.join(MODEL_DIR, 'scaler_lbp.pkl'))\n",
    "        \n",
    "        # Load and preprocess image\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not read image at {image_path}\")\n",
    "            \n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        img = img / 255.0\n",
    "        img = cv2.equalizeHist((img * 255).astype(np.uint8)) / 255.0\n",
    "        \n",
    "        # Extract features\n",
    "        cnn_feat = extract_cnn_features(np.array([img]))\n",
    "        lbp_feat = extract_lbp_features(np.array([img]))\n",
    "        \n",
    "        # Normalize and transform\n",
    "        features = np.hstack([\n",
    "            scaler_cnn.transform(cnn_feat),\n",
    "            scaler_lbp.transform(lbp_feat)\n",
    "        ])\n",
    "        reduced_features = pca.transform(features)\n",
    "        \n",
    "        # Predict\n",
    "        person_id = svm.predict(reduced_features)[0]\n",
    "        confidence = svm.predict_proba(reduced_features).max()\n",
    "        \n",
    "        print(f\"Predicted: Person {person_id} ({confidence*100:.1f}% confidence)\")\n",
    "        return person_id, confidence\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during testing: {str(e)}\")\n",
    "        return None, 0.0\n",
    "\n",
    "# Example usage:\n",
    "test_single_image(r\"C:\\Users\\Selim\\Downloads\\originalimages_part1\\32-06.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2330c813-890d-40d4-9a44-1cf95aa52c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
